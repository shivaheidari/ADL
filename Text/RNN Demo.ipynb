{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBhaN5HM48-b"
      },
      "source": [
        "<center>\n",
        "    <img src=\"https://www.ucalgary.ca/themes/ucalgary/ucws_theme/images/UCalgary.svg\" width='30%'>\n",
        "</center>\n",
        "\n",
        "[comment]: <> (The following line is for the TOPIC of the week)\n",
        "<p style=\"text-align:left;\"><font size='4'><b> Introduction to NLP </b></font></p>\n",
        "\n",
        "---\n",
        "\n",
        "# RNN Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YgPkst451KNX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj9aXIKYxgfX"
      },
      "source": [
        "# Problem definition\n",
        "\n",
        "We will train a model that trying to complete a sentence with RNN.\n",
        "\n",
        "First we need to create a map to the char and index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwZPNMO8QsXG",
        "outputId": "0f70d17b-ce6f-402a-bc24-024289ea70d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['<bos>', 'a', 'b', 'c', 'd', 'e', '<eos>'],\n",
              " ['<bos>', 'x', 'y', 'z', '<eos>', '<pad>', '<pad>']]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[\n",
        " ['<bos>', 'a', 'b', 'c', 'd', 'e', '<eos>'], # len = 512\n",
        " ['<bos>', 'x', 'y', 'z', '<eos>', '<pad>', '<pad>'], # max-length = 512\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# [\n",
        "#     'how are you?' 'good, I am fine.'\n",
        "# ]\n",
        "# '<bos>how are you?<sep>good, I am fine.<eos><pad>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRI0KmZZ37OR",
        "outputId": "37bf40c5-9e9f-467b-833c-3686292ef74e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'o',\n",
              " 1: '<bos>',\n",
              " 2: 'h',\n",
              " 3: 'u',\n",
              " 4: 'm',\n",
              " 5: 'a',\n",
              " 6: 'l',\n",
              " 7: 'e',\n",
              " 8: 'v',\n",
              " 9: 'p',\n",
              " 10: 'c',\n",
              " 11: '<pad>',\n",
              " 12: 'r',\n",
              " 13: 'x',\n",
              " 14: '<eos>',\n",
              " 15: 'i',\n",
              " 16: 'n',\n",
              " 17: 'f',\n",
              " 18: 'w',\n",
              " 19: ' ',\n",
              " 20: 's',\n",
              " 21: 'd',\n",
              " 22: 't',\n",
              " 23: 'g',\n",
              " 24: 'y'}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts = [\n",
        "    'hey how are you', # => 'h','e','y'...'u'\n",
        "    'good i am fine',\n",
        "    'have a nice day',\n",
        "    'this is an example sentence',\n",
        "    'another example sentence is here'\n",
        "]\n",
        "\n",
        "# Join all the sentences together and extract the unique characters from the combined sentences\n",
        "chars = set(list(''.join(texts)) + ['<eos>', '<pad>', '<bos>'])\n",
        "\n",
        "# Creating a dictionary that maps integers to the characters\n",
        "int2char = dict(enumerate(chars))\n",
        "\n",
        "# Creating another dictionary that maps characters to integers\n",
        "char2int = {char: ind for ind, char in int2char.items()}\n",
        "\n",
        "vocab_size = len(int2char)\n",
        "int2char"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lick8RXi4HSg",
        "outputId": "fc449b4a-0a8f-4178-a131-180a15846716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The longest string has 32 characters\n"
          ]
        }
      ],
      "source": [
        "maxlen = len(max(texts, key=len))\n",
        "print(\"The longest string has {} characters\".format(maxlen))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KtFZg0Ix3HA"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "423TnSZm4I5e"
      },
      "outputs": [],
      "source": [
        "# Creating lists that will hold our input and target sequences\n",
        "train_X = []\n",
        "train_Y = []\n",
        "\n",
        "for text in texts:\n",
        "    train_X.append([])\n",
        "    train_Y.append([])\n",
        "    for i in range(maxlen+1):\n",
        "    # for i in range(len(text)):\n",
        "        x = np.zeros(len(char2int))\n",
        "        y = np.zeros(len(char2int))\n",
        "        char_x = '<pad>'\n",
        "        char_y = '<pad>'\n",
        "        if i < len(text) - 1:\n",
        "            char_x = text[i]\n",
        "            char_y = text[i+1]\n",
        "        elif i == len(text) - 1:\n",
        "            char_x = text[i]\n",
        "            char_y = '<eos>'\n",
        "        elif i == len(text):\n",
        "            char_x = '<eos>'\n",
        "        # make it one hot vector\n",
        "        x[char2int[char_x]] = 1\n",
        "        y[char2int[char_y]] = 1\n",
        "        train_X[-1].append(x)\n",
        "        train_Y[-1].append(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vW4rBr6YqR3",
        "outputId": "ff60f3ad-3406-4ef3-aade-42b98a9ac379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[33, 33, 33, 33, 33]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[len(x) for x in train_X]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vygCggEYyXH",
        "outputId": "24e43860-cc93-4df5-b87d-5cd84c906f30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['o',\n",
              " 'o',\n",
              " 'd',\n",
              " ' ',\n",
              " 'i',\n",
              " ' ',\n",
              " 'a',\n",
              " 'm',\n",
              " ' ',\n",
              " 'f',\n",
              " 'i',\n",
              " 'n',\n",
              " 'e',\n",
              " '<eos>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[int2char[np.argmax(x)] for x in train_Y[1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqyXkfH0jLS4",
        "outputId": "18a50afc-d36f-4a8d-b17a-6f12d5f19937"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h -> e\n",
            "e -> y\n",
            "y ->  \n",
            "  -> h\n",
            "h -> o\n",
            "o -> w\n",
            "w ->  \n",
            "  -> a\n",
            "a -> r\n",
            "r -> e\n",
            "e ->  \n",
            "  -> y\n",
            "y -> o\n",
            "o -> u\n",
            "u -> <eos>\n",
            "<eos> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n",
            "<pad> -> <pad>\n"
          ]
        }
      ],
      "source": [
        "sample_id = 0\n",
        "for x,y in zip(train_X[sample_id], train_Y[sample_id]):\n",
        "    print(int2char[x.argmax()], '->', int2char[y.argmax()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqh3_Wte463e",
        "outputId": "a5bf409f-f307-457f-9cf8-7dd201584e63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "_YhPz-4j1NO3"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.W_xa = nn.Linear(input_size, hidden_size)\n",
        "        self.W_aa = nn.Linear(hidden_size, hidden_size)\n",
        "        self.W_ay = nn.Linear(hidden_size, output_size)\n",
        "        # self.g1 = nn.Tanh()\n",
        "        # Better than tanH\n",
        "        self.g1 = nn.ReLU()\n",
        "        # THIS IS INCORRECT!!!!\n",
        "        # Remember CrossEntropyLoss implements softmax FOR YOU!!!!\n",
        "        # self.g2 = nn.Softmax()\n",
        "        self.g2 = nn.Identity()\n",
        "\n",
        "    def forward(self, x, previous_hidden_state):\n",
        "        \"\"\"\n",
        "        x = x^t\n",
        "        previous_hidden_state = a^{t-1}\n",
        "\n",
        "        :return\n",
        "        y^{t}\n",
        "        a^{t}\n",
        "        \"\"\"\n",
        "\n",
        "        current_hidden_state = self.g1(\n",
        "            self.W_aa(previous_hidden_state) +\n",
        "            self.W_xa(x)\n",
        "        )\n",
        "\n",
        "        output = self.g2(\n",
        "            self.W_ay(current_hidden_state)\n",
        "        )\n",
        "\n",
        "        return output, current_hidden_state\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        return torch.zeros(batch_size, self.hidden_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "cOoV8UZq4vWL"
      },
      "outputs": [],
      "source": [
        "# Init the model with hyperparameters\n",
        "model = RNN(\n",
        "    input_size=vocab_size,\n",
        "    hidden_size=50,\n",
        "    output_size=vocab_size,\n",
        ")\n",
        "# We'll also set the model to the device that we defined earlier (default is CPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Define hyperparameters\n",
        "n_epochs = 200\n",
        "lr = 0.0075\n",
        "\n",
        "# Define Loss, Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "schelduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPXFI3kj5Gmq",
        "outputId": "ed00b353-afe2-4599-fb0d-278e7f74cca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10/200............. Loss: 0.0000\n",
            "Epoch: 20/200............. Loss: 0.0000\n",
            "Epoch: 30/200............. Loss: 0.0000\n",
            "Epoch: 40/200............. Loss: 0.0000\n",
            "Epoch: 50/200............. Loss: 0.0000\n",
            "Epoch: 60/200............. Loss: 0.0000\n",
            "Epoch: 70/200............. Loss: 0.0000\n",
            "Epoch: 80/200............. Loss: 0.0000\n",
            "Epoch: 90/200............. Loss: 0.0000\n",
            "Epoch: 100/200............. Loss: 0.0000\n",
            "Epoch: 110/200............. Loss: 0.0000\n",
            "Epoch: 120/200............. Loss: 0.0000\n",
            "Epoch: 130/200............. Loss: 0.0000\n",
            "Epoch: 140/200............. Loss: 0.0000\n",
            "Epoch: 150/200............. Loss: 0.0000\n",
            "Epoch: 160/200............. Loss: 0.0000\n",
            "Epoch: 170/200............. Loss: 0.0000\n",
            "Epoch: 180/200............. Loss: 0.0000\n",
            "Epoch: 190/200............. Loss: 0.0000\n",
            "Epoch: 200/200............. Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# torch.manual_seed(12)\n",
        "# Training Run\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    # loop the sentence\n",
        "    for X, Y in zip(train_X, train_Y):\n",
        "        optimizer.zero_grad()\n",
        "        hidden = model.init_hidden(1).to(device)\n",
        "        losses = []\n",
        "\n",
        "        X = torch.Tensor(X).to(device)\n",
        "        Y = torch.Tensor(Y).to(device)\n",
        "\n",
        "        # feed the input in one by one\n",
        "        # loop the chars\n",
        "        for x, y in zip(X, Y):\n",
        "            x = x.reshape(1, -1) # h\n",
        "            y = y.reshape(1, -1) # e\n",
        "\n",
        "            output, hidden = model(x.view(1,-1), hidden)\n",
        "\n",
        "            loss = criterion(output, y)\n",
        "            losses.append(loss)\n",
        "\n",
        "        sum(losses).backward()\n",
        "        optimizer.step()\n",
        "    schelduler.step()\n",
        "\n",
        "    if epoch%10 == 0:\n",
        "        print('Epoch: {}/{}.............'.format(epoch, n_epochs), end=' ')\n",
        "        print(\"Loss: {:.4f}\".format(loss.item()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvhhz6N7sY1n",
        "outputId": "1ae1ee4c-c684-4b00-84fd-de1d520dae52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "'th'\n",
            "'thi'\n",
            "'this'\n",
            "'this '\n",
            "'this i'\n",
            "'this is'\n",
            "'this is '\n",
            "'this is a'\n",
            "'this is an'\n",
            "'this is an '\n",
            "'this is an e'\n",
            "'this is an ex'\n",
            "'this is an exa'\n",
            "'this is an exam'\n",
            "'this is an examp'\n",
            "'this is an exampl'\n",
            "'this is an example'\n",
            "'this is an example '\n",
            "'this is an example s'\n",
            "'this is an example se'\n",
            "'this is an example sen'\n",
            "'this is an example sent'\n",
            "'this is an example sente'\n",
            "'this is an example senten'\n",
            "'this is an example sentenc'\n",
            "'this is an example sentence'\n",
            "'this is an example sentence<eos>'\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "hidden = model.init_hidden(1).to(device)\n",
        "chars = 't'\n",
        "for _ in range(50):\n",
        "    x = np.zeros(len(char2int))\n",
        "    x[char2int[chars[-1]]] = 1\n",
        "    with torch.no_grad():\n",
        "        output, hidden = model(torch.Tensor(x).view(1, -1).to(device), hidden)\n",
        "\n",
        "    char_id = output.view(-1).argmax().detach().cpu().item()\n",
        "    char = int2char[char_id]\n",
        "    chars += char\n",
        "    print(f\"'{chars}'\")\n",
        "    if char in {'<eos>', '<pad>'}:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "K_AskmniuEPg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
